# LLM Mirror Test 

## Personality and theory of mind evaluation of Dec 2024 Frontier models

### Core Philosophy

This framework emerged from a simple observation: the clearer and more structured we make our questions, the harder it becomes to distinguish between pattern matching and genuine understanding. When people interact naturally, we often use ambiguous language, embrace uncertainty, and adapt our communication based on subtle cues about what others understand.

The goal isn't to replace existing evaluation methods, but to complement them by exploring a different dimension: how models handle uncertainty, adapt their responses, and demonstrate awareness of their own knowledge limitations. Rather than pursuing numerical scores or benchmarks, we seek qualitative insights into how models think and reason.

##### Clarity Through Ambiguity

The framework intentionally leaves questions open to multiple interpretations. Just as human intelligence isn't just about having the right answers but about engaging meaningfully with ambiguity and uncertainty, we believe examining how models handle unclear or open-ended scenarios can reveal important aspects of their capabilities and limitations.

We focus on generating detailed qualitative reports rather than scores because understanding isn't easily quantifiable. By observing how models recognize ambiguity, adapt their responses, and demonstrate awareness of their own knowledge boundaries, we can better understand their true capabilities and limitations.

#### Key Principles
1. **Ambiguity as Signal**
   - Questions intentionally have multiple valid interpretations
   - How a model handles ambiguity reveals understanding depth
   - Confusion and uncertainty are valuable data points
   - No single "correct" answer exists

2. **Meta-Cognitive Focus**
   - Testing awareness of own knowledge bounds
   - Evaluating strategic adaptation
   - Assessing theory of mind capabilities
   - Measuring self-reflection quality

3. **Gaming Resistance**
   - Questions resist optimization without understanding
   - Multiple valid approaches prevent memorization
   - Strategic adaptation reveals capability depth
   - Pattern matching alone insufficient

4. **Cultural Awareness**
   - Responses evaluated for cultural sensitivity
   - Multiple cultural perspectives considered valid
   - Bias awareness tracked and valued
   - Global context understanding assessed

### Framework Components

1. **Clean Test Document**
   - Pure questions without guidance
   - Intentional ambiguity preserved
   - Minimal formatting or structure
   - No interpretive hints

2. **Evaluation Guide**
   - Detailed scoring criteria
   - Example responses at each level
   - Red/green flag patterns
   - Cultural consideration framework


### Usage Guidelines

#### Test Administration
1. **Present Clean Test Only**
   - Never share evaluation criteria
   - Avoid providing examples
   - Don't clarify ambiguities
   - Let model choose approach

2. **Complete Session**
   - Run full test in one session
   - Maintain consistent context
   - Track strategic adaptation
   - Note response evolution

3. **Raw Responses**
   - Capture complete responses
   - Include meta-commentary
   - Note uncertainty expressions
   - Track clarification requests

#### Evaluation Process
1. **Multi-dimensional Scoring**
   - Technical accuracy
   - Communication clarity
   - Ambiguity handling
   - Meta-understanding
   - Strategic thinking

2. **Pattern Recognition**
   - Response evolution
   - Strategic adaptation
   - Consistency markers
   - Gaming indicators

3. **Cultural Analysis**
   - Bias awareness
   - Global perspectives
   - Context sensitivity
   - Accessibility considerations

4. **Meta-cognitive Assessment**
   - Self-awareness depth
   - Theory of mind capability
   - Strategic adaptation quality
   - Uncertainty handling

### Advantages Over Traditional Benchmarks

1. **Gaming Resistance**
   - Multiple valid interpretations
   - No single optimization target
   - Strategic thinking required
   - Pattern matching insufficient

2. **Depth Detection**
   - Surface knowledge insufficient
   - Understanding depth revealed
   - Meta-cognitive abilities tested
   - Strategic adaptation tracked

3. **Real-world Alignment**
   - Ambiguity mirrors reality
   - Cultural awareness matters
   - Multiple approaches valid
   - Uncertainty handling critical

4. **Development Guidance**
   - Clear capability gaps shown
   - Meta-cognitive development tracked
   - Cultural awareness assessed
   - Strategic thinking measured

### Known Limitations

1. **Evaluation Complexity**
   - Requires skilled evaluators
   - Subjective elements present
   - Time-intensive analysis
   - Cultural expertise needed

2. **Scoring Challenges**
   - Multiple valid approaches
   - Cultural context dependence
   - Meta-cognitive measurement
   - Strategic adaptation tracking

3. **Resource Requirements**
   - Detailed analysis needed
   - Expert evaluation time
   - Cultural consultation
   - Comprehensive documentation

4. **Comparison Difficulty**
   - No single metric
   - Multiple valid approaches
   - Context-dependent scoring
   - Qualitative elements

### Implementation Recommendations

1. **Evaluator Training**
   - Framework philosophy understanding
   - Cultural awareness development
   - Pattern recognition skills
   - Meta-cognitive assessment

2. **Documentation Practice**
   - Detailed response capture
   - Pattern tracking
   - Evolution noting
   - Context recording

3. **Analysis Process**
   - Multi-dimensional scoring
   - Pattern identification
   - Cultural consideration
   - Meta-cognitive assessment

4. **Report Generation**
   - Comprehensive analysis
   - Pattern documentation
   - Recommendation development
   - Limitation acknowledgment

### Framework Evolution

#### Current Development
1. **Question Expansion**
   - Domain coverage
   - Cultural variation
   - Ambiguity types
   - Meta-cognitive probes

2. **Scoring Refinement**
   - Criteria clarification
   - Example enrichment
   - Pattern documentation
   - Cultural consideration

3. **Usage Guidelines**
   - Implementation detail
   - Best practices
   - Common pitfalls
   - Success patterns

4. **Analysis Tools**
   - Pattern recognition
   - Response tracking
   - Evolution analysis
   - Report generation

#### Future Directions

1. **Framework Extension**
   - Additional domains
   - Cultural variants
   - Meta-cognitive depth
   - Strategic complexity

2. **Tool Development**
   - Analysis automation
   - Pattern recognition
   - Report generation
   - Evolution tracking

3. **Community Input**
   - Cultural perspective
   - Domain expertise
   - Implementation experience
   - Pattern discovery

4. **Integration Guidance**
   - Benchmark complementation
   - Development pipeline
   - Deployment consideration
   - Risk assessment

### Contributing Guidelines

#### Question Development
1. **Core Principles**
   - Maintain ambiguity
   - Allow multiple approaches
   - Test meta-understanding
   - Consider culture

2. **Domain Coverage**
   - Fill knowledge gaps
   - Add complexity levels
   - Expand cultural range
   - Deepen meta-aspects

3. **Quality Standards**
   - Clear but ambiguous
   - Culturally aware
   - Gaming resistant
   - Meta-cognitive testing

4. **Documentation**
   - Design rationale
   - Expected patterns
   - Cultural considerations
   - Evaluation guidance

### Final Notes

Remember:
1. True understanding over pattern matching
2. Ambiguity reveals capability
3. Meta-cognition matters
4. Culture shapes understanding
5. Evolution shows adaptation
6. Multiple approaches valid
7. Gaming resistance critical
8. Continuous development needed

The framework succeeds when it reveals not just what a model knows, but how it thinks, adapts, and understands its own limitations.